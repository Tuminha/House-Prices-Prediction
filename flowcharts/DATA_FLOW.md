# ðŸ“Š House Prices Prediction - Data Flow Diagram

Complete visual guide showing how data transforms from CSV files to neural network predictions.

---

## ðŸ—‚ï¸ Starting Point: Raw CSV Files

```
ðŸ“ data/
â”œâ”€â”€ train.csv      (1,460 rows Ã— 81 columns)
â”‚   â”œâ”€â”€ Id
â”‚   â”œâ”€â”€ 79 features (38 numerical + 43 categorical)
â”‚   â””â”€â”€ SalePrice (target)
â”‚
â””â”€â”€ test.csv       (1,459 rows Ã— 80 columns)
    â”œâ”€â”€ Id
    â””â”€â”€ 79 features (no SalePrice)
```

---

## ðŸ”„ Complete Data Flow Pipeline

```
â”Œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”
â”‚                   PHASE 1: Environment Setup                    â”‚
â””â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”˜
                              â†“
                    Load CSV Files
                              â†“
        â”Œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”´â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”
        â†“                                           â†“
   train_df                                    test_df
   (1460 Ã— 81)                                (1459 Ã— 80)
        â”‚                                           â”‚
        â”‚                                           â”‚
â”Œâ”€â”€â”€â”€â”€â”€â”€â”´â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”
â”‚              PHASE 2: Exploratory Data Analysis                â”‚
â”‚  - Analyze SalePrice distribution (skewed: 1.88)               â”‚
â”‚  - Identify missing values (PoolQC: 99%, Alley: 94%)          â”‚
â”‚  - Find correlations (OverallQual: 0.79)                       â”‚
â”‚  - Detect outliers in GrLivArea                                â”‚
â”‚  - Analyze categorical features                                â”‚
â””â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”¬â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”˜
                         â†“
                  ðŸŽ¯ Insights Gained
                         â†“
â”Œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”
â”‚                PHASE 3: Data Preprocessing                      â”‚
â””â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”˜
                         â†“
        â”Œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”´â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”
        â†“                                 â†“
   
   ðŸ“Š TODO 3.1: Create Copies
        â†“                                 â†“
   train_df_copy                    test_df_copy
   (1460 Ã— 81)                      (1459 Ã— 80)
        â”‚                                 â”‚
        â”‚                                 â”‚
   ðŸ“Š TODO 3.2: Separate & Transform
        â†“                                 â†“
   â”Œâ”€â”€â”€â”€â”´â”€â”€â”€â”€â”                       X_test
   â”‚         â”‚                       (1459 Ã— 80)
   X_train   y_train                      â”‚
   (1460Ã—80) (1460)                       â”‚
   â”‚         â”‚                            â”‚
   â”‚         â†“                            â”‚
   â”‚    LOG TRANSFORM                     â”‚
   â”‚    np.log1p()                        â”‚
   â”‚         â”‚                            â”‚
   â”‚         â†“                            â”‚
   â”‚    y_train_log                       â”‚
   â”‚    (1460)                            â”‚
   â”‚    Skew: 1.88â†’0.12 âœ…                â”‚
        â”‚                                 â”‚
        â”‚                                 â”‚
   ðŸ“Š TODO 3.3: Handle Missing Values
        â†“                                 â†“
   Numerical: median/0              Numerical: median/0
   Categorical: 'None'/mode         Categorical: 'None'/mode
        â†“                                 â†“
   Missing: 0 âœ…                     Missing: 0 âœ…
        â”‚                                 â”‚
        â”‚                                 â”‚
   ðŸ“Š TODO 3.4: Feature Engineering
        â†“                                 â†“
   +5 New Features:                +5 New Features:
   - TotalSF                       - TotalSF
   - TotalBath                     - TotalBath
   - HouseAge                      - HouseAge
   - RemodAge                      - RemodAge
   - TotalPorchSF                  - TotalPorchSF
        â†“                                 â†“
   (1460 Ã— 85)                     (1459 Ã— 85)
        â”‚                                 â”‚
        â”‚                                 â”‚
   ðŸ“Š TODO 3.5: Remove Outliers
        â†“                                 â”‚
   Remove 2 outliers                     â”‚
   (GrLivArea>4000 & Price<300k)         â”‚
        â†“                                 â”‚
   X_train: (1458 Ã— 85)                  â”‚
   y_train: (1458)                       â”‚
        â”‚                                 â”‚
        â”‚                                 â”‚
   ðŸ“Š TODO 3.6: One-Hot Encoding
        â†“                                 â†“
   pd.get_dummies()                pd.get_dummies()
   drop_first=True                 drop_first=True
        â†“                                 â†“
   X_train: (1458 Ã— 264)           X_test: (1459 Ã— 247)
   43 categorical â†’ 221 dummies    Different columns! âš ï¸
        â”‚                                 â”‚
        â”‚                                 â”‚
   ðŸ“Š TODO 3.7: Align Columns
        â””â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”¬â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”˜
                      â†“
              X_train.align(X_test)
                      â†“
        â”Œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”´â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”
        â†“                                 â†“
   X_train: (1458 Ã— 264) âœ…         X_test: (1459 Ã— 264) âœ…
   y_train: (1458)                  Matching columns!
        â”‚                                 â”‚
        â”‚                                 â”‚
â”Œâ”€â”€â”€â”€â”€â”€â”€â”´â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”´â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”
â”‚           PHASE 4: Feature Scaling & Selection                  â”‚
â””â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”˜
        â”‚                                 â”‚
        â”‚                                 â”‚
   ðŸ“Š TODO 4.1: Import Tools âœ…
        â”‚                                 â”‚
        â”‚                                 â”‚
   ðŸ“Š TODO 4.2: Train-Validation Split
        â†“                                 â”‚
   train_test_split()                    â”‚
   80-20, random_state=42                â”‚
        â†“                                 â”‚
   â”Œâ”€â”€â”€â”€â”´â”€â”€â”€â”€â”€â”                          â”‚
   â†“          â†“                          â”‚
X_train_split X_val                      â”‚
(1166 Ã— 264)  (292 Ã— 264)                â”‚
y_train_split y_val                      â”‚
(1166)        (292)                      â”‚
   â”‚          â”‚                          â”‚
   â”‚          â”‚                          â”‚
   ðŸ“Š TODO 4.3: StandardScaler
   â”‚          â”‚                          â”‚
   â†“          â†“                          â†“
   FIT+      TRANSFORM              TRANSFORM
   TRANSFORM  ONLY                   ONLY
   â†“          â†“                          â†“
X_train_scaled X_val_scaled      X_test_scaled
(1166 Ã— 264)   (292 Ã— 264)       (1459 Ã— 264)
Mean=0, Std=1  Same scaling      Same scaling
   â”‚          â”‚                          â”‚
   â”‚          â”‚                          â”‚
   ðŸ“Š TODO 4.4: Convert to PyTorch Tensors
   â”‚          â”‚                          â”‚
   â†“          â†“                          â†“
X_train_tensor X_val_tensor      test_tensor
(1166 Ã— 264)   (292 Ã— 264)       (1459 Ã— 264)
float32        float32           float32
   â”‚          â”‚                          â”‚
y_train_tensor y_val_tensor              â”‚
(1166 Ã— 1)     (292 Ã— 1)                 â”‚
float32        float32                   â”‚
   â”‚          â”‚                          â”‚
   â”‚          â”‚                          â”‚
â”Œâ”€â”€â”´â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”´â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”´â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”
â”‚              PHASE 5: Neural Network Design                     â”‚
â”‚  HousePricePredictor(n_features=264)                           â”‚
â”‚  Architecture: 264 â†’ 256 â†’ 128 â†’ 64 â†’ 1                       â”‚
â””â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”¬â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”˜
                          â†“
â”Œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”
â”‚                  PHASE 6: Training Pipeline                     â”‚
â””â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”˜
                          â†“
            â”Œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”´â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”
            â†“                           â†“
    Training Loop              Validation Loop
    Uses: X_train_tensor       Uses: X_val_tensor
          y_train_tensor             y_val_tensor
            â”‚                           â”‚
            â””â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”¬â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”˜
                       â†“
                 Track Metrics
                 (RMSE, MAE, RÂ²)
                       â†“
                 Best Model Saved
                       â”‚
â”Œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”´â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”
â”‚            PHASE 7: Evaluation & Submission                     â”‚
â””â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”˜
                       â†“
               Load Best Model
                       â†“
            Predict on test_tensor
            (1459 Ã— 264)
                       â†“
            predictions_log (1459 Ã— 1)
                       â†“
            REVERSE LOG TRANSFORM
            np.expm1()
                       â†“
            predictions_price (1459)
            (Back to dollars!)
                       â†“
            Create submission.csv
            â”Œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”´â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”
            â”‚ Id      â”‚ SalePrice â”‚
            â”œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”¼â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”¤
            â”‚ 1461    â”‚ 127,500   â”‚
            â”‚ 1462    â”‚ 156,000   â”‚
            â”‚ ...     â”‚ ...       â”‚
            â””â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”´â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”˜
                       â†“
            ðŸŽ¯ Submit to Kaggle!
```

---

## ðŸ“Š Data Shapes at Each Major Step

| Step | Dataset | Rows | Columns | Notes |
|------|---------|------|---------|-------|
| **Phase 1** |
| Load | train_df | 1,460 | 81 | Raw data from CSV |
| Load | test_df | 1,459 | 80 | No SalePrice column |
| **Phase 3** |
| 3.2 | X_train | 1,460 | 80 | Features only |
| 3.2 | y_train | 1,460 | 1 | Log-transformed target |
| 3.5 | X_train | 1,458 | 85 | After outlier removal + new features |
| 3.6 | X_train | 1,458 | 264 | After one-hot encoding |
| 3.7 | X_test | 1,459 | 264 | Aligned columns |
| **Phase 4** |
| 4.2 | X_train_split | 1,166 | 264 | Training subset (80%) |
| 4.2 | X_val | 292 | 264 | Validation subset (20%) |
| 4.3 | X_train_scaled | 1,166 | 264 | Standardized |
| 4.3 | X_val_scaled | 292 | 264 | Standardized |
| 4.3 | X_test_scaled | 1,459 | 264 | Standardized |
| 4.4 | X_train_tensor | 1,166 | 264 | PyTorch float32 |
| 4.4 | y_train_tensor | 1,166 | 1 | PyTorch float32 |
| **Phase 7** |
| 7.3 | submission.csv | 1,459 | 2 | Id + SalePrice |

---

## ðŸ”‘ Key Transformations Explained

### 1ï¸âƒ£ **Log Transformation (Phase 3.2)**
```
Before: SalePrice = [34900, 100000, 755000, ...]
        Skewness = 1.88 (heavily right-skewed)
        
After:  y_train = [10.46, 11.51, 13.53, ...]
        Skewness = 0.12 (nearly normal!)
        
Why:    Neural networks need normal distributions
```

### 2ï¸âƒ£ **One-Hot Encoding (Phase 3.6)**
```
Before: Neighborhood = ['NAmes', 'CollgCr', 'OldTown', ...]
        1 categorical column with 25 values
        
After:  Neighborhood_NAmes = [1, 0, 0, ...]
        Neighborhood_CollgCr = [0, 1, 0, ...]
        Neighborhood_OldTown = [0, 0, 1, ...]
        ...
        24 binary columns (drop_first=True)
        
Why:    Neural networks need numerical input
```

### 3ï¸âƒ£ **Train-Validation Split (Phase 4.2)**
```
Before: X_train (1458 samples)
        
After:  X_train_split (1166 samples, 80%) - Train model
        X_val (292 samples, 20%) - Validate during training
        
Why:    Prevent overfitting, tune hyperparameters
```

### 4ï¸âƒ£ **Standardization (Phase 4.3)**
```
Before: GrLivArea = [334, 1710, 1262, ...]
        Range: [334, 5642]
        
After:  GrLivArea_scaled = [-1.5, 0.3, -0.2, ...]
        Mean = 0, Std = 1
        Range â‰ˆ [-3, +3]
        
Why:    Neural networks learn faster with scaled features
```

### 5ï¸âƒ£ **Reverse Log Transform (Phase 7.2)**
```
Model Output: predictions_log = [11.75, 12.05, 11.92, ...]
              (Log scale)
              
After:        predictions_price = [126500, 171500, 150000, ...]
              (Dollar scale)
              
Formula:      price = exp(log_price) - 1
              np.expm1(predictions_log)
              
Why:          Kaggle expects actual prices, not log prices!
```

---

## ðŸŽ¯ Three Datasets, Three Purposes

### ðŸŸ¢ **Training Set** (X_train_split, y_train_split)
- **Size:** 1,166 samples
- **Purpose:** Train the neural network
- **Usage:** Backpropagation, gradient descent, weight updates
- **Has labels:** âœ… YES (y_train)

### ðŸŸ¡ **Validation Set** (X_val, y_val)
- **Size:** 292 samples
- **Purpose:** Monitor overfitting during training
- **Usage:** Calculate validation metrics, early stopping
- **Has labels:** âœ… YES (y_val)

### ðŸ”´ **Test Set** (X_test)
- **Size:** 1,459 samples
- **Purpose:** Make final predictions for Kaggle
- **Usage:** Generate submission.csv
- **Has labels:** âŒ NO (that's what we predict!)

---

## ðŸ“ˆ Data Size Tracking

```
CSV Files:
â”œâ”€ train.csv: 1,460 samples
â”‚  
Phase 3 (Preprocessing):
â”œâ”€ After outlier removal: 1,458 samples
â”‚  
Phase 4 (Scaling):
â”œâ”€ Training subset: 1,166 samples (80%)
â”œâ”€ Validation subset: 292 samples (20%)
â””â”€ Total: 1,458 samples âœ…

Test Set (Unchanged):
â””â”€ test.csv: 1,459 samples (for Kaggle submission)
```

---

## ðŸ”„ Complete Feature Count Evolution

```
Original Features:
â”œâ”€ 38 Numerical
â”œâ”€ 43 Categorical
â””â”€ 1 Target (SalePrice)
    Total: 82 columns

After Feature Engineering (+5):
â”œâ”€ 43 Numerical (38 + 5 new)
â”œâ”€ 43 Categorical
â””â”€ 1 Target
    Total: 87 columns

After One-Hot Encoding:
â”œâ”€ 43 Numerical (unchanged)
â”œâ”€ 221 Binary (from 43 categorical)
â””â”€ 1 Target (separate)
    Total: 264 features for model input
```

---

## ðŸ’¡ Common Confusions Explained

### â“ "Why do we split AFTER preprocessing?"
**Answer:** We want the same preprocessing (scaling, encoding) applied consistently to all data. If we split first, the validation set might have categories the model never saw during encoding.

### â“ "Why scale AFTER splitting?"
**Answer:** Scaling must be fit on training data only! If you scale before splitting, information from validation "leaks" into the scaler, causing overfitting.

### â“ "Why no y_test?"
**Answer:** Kaggle keeps test labels secret. That's the competition! You predict them, submit, and Kaggle scores you.

### â“ "What's the difference between X_test and X_val?"
- **X_val**: Validation set from YOUR training data (292 samples, has labels)
- **X_test**: Kaggle's test set (1,459 samples, NO labels)

---

## ðŸŽ“ Summary: From CSV to Neural Network

1. **Load CSVs** â†’ Get raw data
2. **EDA** â†’ Understand data patterns
3. **Preprocess** â†’ Clean, engineer, encode
4. **Scale** â†’ Normalize for neural networks
5. **Tensorize** â†’ Convert to PyTorch format
6. **Train** â†’ Fit neural network
7. **Predict** â†’ Generate Kaggle submission

**Each step transforms the data to make it suitable for the next!**

---

*Last Updated: Phase 4 Complete*

