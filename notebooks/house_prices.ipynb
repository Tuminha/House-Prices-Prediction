{
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "# üè† House Prices - Advanced Regression Techniques\n",
        "\n",
        "**Learning Project**: Predicting house sale prices using Neural Networks  \n",
        "**Kaggle Competition**: [House Prices: Advanced Regression Techniques](https://www.kaggle.com/c/house-prices-advanced-regression-techniques)\n",
        "\n",
        "---\n",
        "\n",
        "## üìö What You'll Learn\n",
        "\n",
        "This project builds on your Digit Recognizer experience but introduces **regression** instead of classification:\n",
        "\n",
        "| Concept | Classification (Digit Recognizer) | Regression (House Prices) |\n",
        "|---------|-----------------------------------|---------------------------|\n",
        "| **Output** | Class label (0-9) | Continuous value (price) |\n",
        "| **Output Layer** | 10 neurons (softmax) | 1 neuron (no activation) |\n",
        "| **Loss Function** | CrossEntropyLoss | MSELoss / L1Loss |\n",
        "| **Metrics** | Accuracy | RMSE, MAE, R¬≤ |\n",
        "| **Prediction** | `torch.max(output, 1)` | `output.squeeze()` |\n",
        "\n",
        "---\n",
        "\n",
        "## üìã Project Structure\n",
        "\n",
        "This notebook is divided into **7 phases**. Each phase contains:\n",
        "- üìñ **Explanation** of concepts\n",
        "- üéØ **Learning objectives** for that phase\n",
        "- ‚úÖ **TODO blocks** where you'll write code\n",
        "- üí° **Hints** to guide you (not complete solutions!)\n",
        "\n",
        "Work through each phase step by step. Ask for help if you get stuck!\n",
        "\n",
        "---"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "# Phase 1: Environment Setup ‚úÖ\n",
        "\n",
        "## üéØ Learning Objectives\n",
        "- Import necessary libraries for data science and deep learning\n",
        "- Check PyTorch installation and GPU availability\n",
        "- Load the dataset from CSV files\n",
        "- Understand the data structure\n",
        "\n",
        "## üìñ Key Concepts\n",
        "\n",
        "**Libraries we'll use:**\n",
        "- `pandas` - Data manipulation and analysis\n",
        "- `numpy` - Numerical operations\n",
        "- `matplotlib` & `seaborn` - Data visualization\n",
        "- `torch` - Neural network framework\n",
        "- `sklearn` - Traditional ML algorithms and preprocessing tools\n",
        "\n",
        "---"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 1,
      "metadata": {},
      "outputs": [],
      "source": [
        "# TODO 1.1: Import Libraries\n",
        "# Import the following:\n",
        "# - pandas as pd\n",
        "# - numpy as np\n",
        "# - matplotlib.pyplot as plt\n",
        "# - seaborn as sns\n",
        "# - torch (PyTorch)\n",
        "# - torch.nn as nn\n",
        "# - torch.optim for optimizers\n",
        "\n",
        "# HINT: Use 'import X as Y' syntax for cleaner code\n",
        "\n",
        "import pandas as pd\n",
        "import numpy as np\n",
        "import matplotlib.pyplot as plt\n",
        "import seaborn as sns\n",
        "import torch\n",
        "import torch.nn as nn\n",
        "import torch.optim\n",
        "\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 2,
      "metadata": {},
      "outputs": [],
      "source": [
        "# TODO 1.2: Configure Display Settings\n",
        "# Set up nice display settings:\n",
        "# - Set seaborn style to 'darkgrid'\n",
        "# - Set matplotlib figure size to (12, 6) by default\n",
        "# - Set pandas display options to show all columns\n",
        "\n",
        "# HINT: Use sns.set_style(), plt.rcParams['figure.figsize'], pd.set_option()\n",
        "\n",
        "sns.set_style('darkgrid')\n",
        "plt.rcParams['figure.figsize'] = (12, 6)\n",
        "pd.set_option('display.max_columns', None)\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 3,
      "metadata": {},
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "PyTorch version: 2.8.0\n",
            "CUDA available: False\n",
            "Device being used: cpu\n"
          ]
        }
      ],
      "source": [
        "# TODO 1.3: Check PyTorch Setup\n",
        "# Print the following:\n",
        "# - PyTorch version\n",
        "# - CUDA availability (GPU support)\n",
        "# - Device being used (cuda or cpu)\n",
        "\n",
        "# HINT: torch.__version__, torch.cuda.is_available(), torch.device()\n",
        "\n",
        "print(f\"PyTorch version: {torch.__version__}\")\n",
        "cuda_available = torch.cuda.is_available()\n",
        "print(f\"CUDA available: {cuda_available}\")\n",
        "device = torch.device(\"cuda\" if cuda_available else \"cpu\")\n",
        "print(f\"Device being used: {device}\")\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 5,
      "metadata": {},
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "Shape of the train dataset: (1460, 81)\n",
            "\n",
            "Shape of the test dataset: (1459, 80)\n",
            "\n",
            "5 first rows of the training data:\n",
            "   Id  MSSubClass MSZoning  LotFrontage  LotArea Street Alley LotShape  \\\n",
            "0   1          60       RL         65.0     8450   Pave   NaN      Reg   \n",
            "1   2          20       RL         80.0     9600   Pave   NaN      Reg   \n",
            "2   3          60       RL         68.0    11250   Pave   NaN      IR1   \n",
            "3   4          70       RL         60.0     9550   Pave   NaN      IR1   \n",
            "4   5          60       RL         84.0    14260   Pave   NaN      IR1   \n",
            "\n",
            "  LandContour Utilities LotConfig LandSlope Neighborhood Condition1  \\\n",
            "0         Lvl    AllPub    Inside       Gtl      CollgCr       Norm   \n",
            "1         Lvl    AllPub       FR2       Gtl      Veenker      Feedr   \n",
            "2         Lvl    AllPub    Inside       Gtl      CollgCr       Norm   \n",
            "3         Lvl    AllPub    Corner       Gtl      Crawfor       Norm   \n",
            "4         Lvl    AllPub       FR2       Gtl      NoRidge       Norm   \n",
            "\n",
            "  Condition2 BldgType HouseStyle  OverallQual  OverallCond  YearBuilt  \\\n",
            "0       Norm     1Fam     2Story            7            5       2003   \n",
            "1       Norm     1Fam     1Story            6            8       1976   \n",
            "2       Norm     1Fam     2Story            7            5       2001   \n",
            "3       Norm     1Fam     2Story            7            5       1915   \n",
            "4       Norm     1Fam     2Story            8            5       2000   \n",
            "\n",
            "   YearRemodAdd RoofStyle RoofMatl Exterior1st Exterior2nd MasVnrType  \\\n",
            "0          2003     Gable  CompShg     VinylSd     VinylSd    BrkFace   \n",
            "1          1976     Gable  CompShg     MetalSd     MetalSd        NaN   \n",
            "2          2002     Gable  CompShg     VinylSd     VinylSd    BrkFace   \n",
            "3          1970     Gable  CompShg     Wd Sdng     Wd Shng        NaN   \n",
            "4          2000     Gable  CompShg     VinylSd     VinylSd    BrkFace   \n",
            "\n",
            "   MasVnrArea ExterQual ExterCond Foundation BsmtQual BsmtCond BsmtExposure  \\\n",
            "0       196.0        Gd        TA      PConc       Gd       TA           No   \n",
            "1         0.0        TA        TA     CBlock       Gd       TA           Gd   \n",
            "2       162.0        Gd        TA      PConc       Gd       TA           Mn   \n",
            "3         0.0        TA        TA     BrkTil       TA       Gd           No   \n",
            "4       350.0        Gd        TA      PConc       Gd       TA           Av   \n",
            "\n",
            "  BsmtFinType1  BsmtFinSF1 BsmtFinType2  BsmtFinSF2  BsmtUnfSF  TotalBsmtSF  \\\n",
            "0          GLQ         706          Unf           0        150          856   \n",
            "1          ALQ         978          Unf           0        284         1262   \n",
            "2          GLQ         486          Unf           0        434          920   \n",
            "3          ALQ         216          Unf           0        540          756   \n",
            "4          GLQ         655          Unf           0        490         1145   \n",
            "\n",
            "  Heating HeatingQC CentralAir Electrical  1stFlrSF  2ndFlrSF  LowQualFinSF  \\\n",
            "0    GasA        Ex          Y      SBrkr       856       854             0   \n",
            "1    GasA        Ex          Y      SBrkr      1262         0             0   \n",
            "2    GasA        Ex          Y      SBrkr       920       866             0   \n",
            "3    GasA        Gd          Y      SBrkr       961       756             0   \n",
            "4    GasA        Ex          Y      SBrkr      1145      1053             0   \n",
            "\n",
            "   GrLivArea  BsmtFullBath  BsmtHalfBath  FullBath  HalfBath  BedroomAbvGr  \\\n",
            "0       1710             1             0         2         1             3   \n",
            "1       1262             0             1         2         0             3   \n",
            "2       1786             1             0         2         1             3   \n",
            "3       1717             1             0         1         0             3   \n",
            "4       2198             1             0         2         1             4   \n",
            "\n",
            "   KitchenAbvGr KitchenQual  TotRmsAbvGrd Functional  Fireplaces FireplaceQu  \\\n",
            "0             1          Gd             8        Typ           0         NaN   \n",
            "1             1          TA             6        Typ           1          TA   \n",
            "2             1          Gd             6        Typ           1          TA   \n",
            "3             1          Gd             7        Typ           1          Gd   \n",
            "4             1          Gd             9        Typ           1          TA   \n",
            "\n",
            "  GarageType  GarageYrBlt GarageFinish  GarageCars  GarageArea GarageQual  \\\n",
            "0     Attchd       2003.0          RFn           2         548         TA   \n",
            "1     Attchd       1976.0          RFn           2         460         TA   \n",
            "2     Attchd       2001.0          RFn           2         608         TA   \n",
            "3     Detchd       1998.0          Unf           3         642         TA   \n",
            "4     Attchd       2000.0          RFn           3         836         TA   \n",
            "\n",
            "  GarageCond PavedDrive  WoodDeckSF  OpenPorchSF  EnclosedPorch  3SsnPorch  \\\n",
            "0         TA          Y           0           61              0          0   \n",
            "1         TA          Y         298            0              0          0   \n",
            "2         TA          Y           0           42              0          0   \n",
            "3         TA          Y           0           35            272          0   \n",
            "4         TA          Y         192           84              0          0   \n",
            "\n",
            "   ScreenPorch  PoolArea PoolQC Fence MiscFeature  MiscVal  MoSold  YrSold  \\\n",
            "0            0         0    NaN   NaN         NaN        0       2    2008   \n",
            "1            0         0    NaN   NaN         NaN        0       5    2007   \n",
            "2            0         0    NaN   NaN         NaN        0       9    2008   \n",
            "3            0         0    NaN   NaN         NaN        0       2    2006   \n",
            "4            0         0    NaN   NaN         NaN        0      12    2008   \n",
            "\n",
            "  SaleType SaleCondition  SalePrice  \n",
            "0       WD        Normal     208500  \n",
            "1       WD        Normal     181500  \n",
            "2       WD        Normal     223500  \n",
            "3       WD       Abnorml     140000  \n",
            "4       WD        Normal     250000  \n"
          ]
        }
      ],
      "source": [
        "# TODO 1.4: Load the Data\n",
        "# Load the training data from '../data/train.csv' into a DataFrame called 'train_df'\n",
        "# Load the test data from '../data/test.csv' into a DataFrame called 'test_df'\n",
        "# Display the first 5 rows of training data\n",
        "# Print the shape of both datasets\n",
        "\n",
        "# HINT: Use pd.read_csv(), .head(), .shape\n",
        "\n",
        "# Your code here:\n",
        "path_train = \"../data/train.csv\"\n",
        "path_test = \"../data/test.csv\"\n",
        "\n",
        "train_df = pd.read_csv(path_train)\n",
        "test_df = pd.read_csv(path_test)\n",
        "\n",
        "print(\"Shape of the train dataset:\", train_df.shape)\n",
        "print()\n",
        "print(\"Shape of the test dataset:\", test_df.shape)\n",
        "print()\n",
        "print(\"5 first rows of the training data:\")\n",
        "print(train_df.head())\n",
        "\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 19,
      "metadata": {},
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "==================================================\n",
            "DATASET INFORMATION\n",
            "==================================================\n",
            "<class 'pandas.core.frame.DataFrame'>\n",
            "RangeIndex: 1460 entries, 0 to 1459\n",
            "Data columns (total 81 columns):\n",
            " #   Column         Non-Null Count  Dtype  \n",
            "---  ------         --------------  -----  \n",
            " 0   Id             1460 non-null   int64  \n",
            " 1   MSSubClass     1460 non-null   int64  \n",
            " 2   MSZoning       1460 non-null   object \n",
            " 3   LotFrontage    1201 non-null   float64\n",
            " 4   LotArea        1460 non-null   int64  \n",
            " 5   Street         1460 non-null   object \n",
            " 6   Alley          91 non-null     object \n",
            " 7   LotShape       1460 non-null   object \n",
            " 8   LandContour    1460 non-null   object \n",
            " 9   Utilities      1460 non-null   object \n",
            " 10  LotConfig      1460 non-null   object \n",
            " 11  LandSlope      1460 non-null   object \n",
            " 12  Neighborhood   1460 non-null   object \n",
            " 13  Condition1     1460 non-null   object \n",
            " 14  Condition2     1460 non-null   object \n",
            " 15  BldgType       1460 non-null   object \n",
            " 16  HouseStyle     1460 non-null   object \n",
            " 17  OverallQual    1460 non-null   int64  \n",
            " 18  OverallCond    1460 non-null   int64  \n",
            " 19  YearBuilt      1460 non-null   int64  \n",
            " 20  YearRemodAdd   1460 non-null   int64  \n",
            " 21  RoofStyle      1460 non-null   object \n",
            " 22  RoofMatl       1460 non-null   object \n",
            " 23  Exterior1st    1460 non-null   object \n",
            " 24  Exterior2nd    1460 non-null   object \n",
            " 25  MasVnrType     588 non-null    object \n",
            " 26  MasVnrArea     1452 non-null   float64\n",
            " 27  ExterQual      1460 non-null   object \n",
            " 28  ExterCond      1460 non-null   object \n",
            " 29  Foundation     1460 non-null   object \n",
            " 30  BsmtQual       1423 non-null   object \n",
            " 31  BsmtCond       1423 non-null   object \n",
            " 32  BsmtExposure   1422 non-null   object \n",
            " 33  BsmtFinType1   1423 non-null   object \n",
            " 34  BsmtFinSF1     1460 non-null   int64  \n",
            " 35  BsmtFinType2   1422 non-null   object \n",
            " 36  BsmtFinSF2     1460 non-null   int64  \n",
            " 37  BsmtUnfSF      1460 non-null   int64  \n",
            " 38  TotalBsmtSF    1460 non-null   int64  \n",
            " 39  Heating        1460 non-null   object \n",
            " 40  HeatingQC      1460 non-null   object \n",
            " 41  CentralAir     1460 non-null   object \n",
            " 42  Electrical     1459 non-null   object \n",
            " 43  1stFlrSF       1460 non-null   int64  \n",
            " 44  2ndFlrSF       1460 non-null   int64  \n",
            " 45  LowQualFinSF   1460 non-null   int64  \n",
            " 46  GrLivArea      1460 non-null   int64  \n",
            " 47  BsmtFullBath   1460 non-null   int64  \n",
            " 48  BsmtHalfBath   1460 non-null   int64  \n",
            " 49  FullBath       1460 non-null   int64  \n",
            " 50  HalfBath       1460 non-null   int64  \n",
            " 51  BedroomAbvGr   1460 non-null   int64  \n",
            " 52  KitchenAbvGr   1460 non-null   int64  \n",
            " 53  KitchenQual    1460 non-null   object \n",
            " 54  TotRmsAbvGrd   1460 non-null   int64  \n",
            " 55  Functional     1460 non-null   object \n",
            " 56  Fireplaces     1460 non-null   int64  \n",
            " 57  FireplaceQu    770 non-null    object \n",
            " 58  GarageType     1379 non-null   object \n",
            " 59  GarageYrBlt    1379 non-null   float64\n",
            " 60  GarageFinish   1379 non-null   object \n",
            " 61  GarageCars     1460 non-null   int64  \n",
            " 62  GarageArea     1460 non-null   int64  \n",
            " 63  GarageQual     1379 non-null   object \n",
            " 64  GarageCond     1379 non-null   object \n",
            " 65  PavedDrive     1460 non-null   object \n",
            " 66  WoodDeckSF     1460 non-null   int64  \n",
            " 67  OpenPorchSF    1460 non-null   int64  \n",
            " 68  EnclosedPorch  1460 non-null   int64  \n",
            " 69  3SsnPorch      1460 non-null   int64  \n",
            " 70  ScreenPorch    1460 non-null   int64  \n",
            " 71  PoolArea       1460 non-null   int64  \n",
            " 72  PoolQC         7 non-null      object \n",
            " 73  Fence          281 non-null    object \n",
            " 74  MiscFeature    54 non-null     object \n",
            " 75  MiscVal        1460 non-null   int64  \n",
            " 76  MoSold         1460 non-null   int64  \n",
            " 77  YrSold         1460 non-null   int64  \n",
            " 78  SaleType       1460 non-null   object \n",
            " 79  SaleCondition  1460 non-null   object \n",
            " 80  SalePrice      1460 non-null   int64  \n",
            "dtypes: float64(3), int64(35), object(43)\n",
            "memory usage: 924.0+ KB\n",
            "\n",
            "==================================================\n",
            "BASIC STATISTICS\n",
            "==================================================\n",
            "\n",
            "==================================================\n",
            "DATA TYPES BREAKDOWN\n",
            "==================================================\n",
            "Numerical columns (float): 3\n",
            "Numerical columns (int): 35\n",
            "Categorical columns (object): 43\n",
            "\n",
            "Total columns: 81\n"
          ]
        }
      ],
      "source": [
        "# TODO 1.5: Basic Dataset Information\n",
        "# Display:\n",
        "# - Column names and data types using .info()\n",
        "# - Basic statistics using .describe()\n",
        "# - Number of numerical vs categorical columns\n",
        "\n",
        "# HINT: Use .info(), .describe(), .select_dtypes()\n",
        "\n",
        "# Your code here:\n",
        "# TODO 1.5: Basic Dataset Information\n",
        "\n",
        "# 1. Column names and data types\n",
        "print(\"=\" * 50)\n",
        "print(\"DATASET INFORMATION\")\n",
        "print(\"=\" * 50)\n",
        "train_df.info()\n",
        "\n",
        "print(\"\\n\" + \"=\" * 50)\n",
        "print(\"BASIC STATISTICS\")\n",
        "print(\"=\" * 50)\n",
        "train_df.describe()  # ‚Üê Add this!\n",
        "\n",
        "print(\"\\n\" + \"=\" * 50)\n",
        "print(\"DATA TYPES BREAKDOWN\")\n",
        "print(\"=\" * 50)\n",
        "print(f\"Numerical columns (float): {len(train_df.select_dtypes(float).columns)}\")\n",
        "print(f\"Numerical columns (int): {len(train_df.select_dtypes(int).columns)}\")\n",
        "print(f\"Categorical columns (object): {len(train_df.select_dtypes(object).columns)}\")\n",
        "print(f\"\\nTotal columns: {len(train_df.columns)}\")\n",
        "\n"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "---\n",
        "\n",
        "## ‚úÖ Phase 1 Checklist - COMPLETE! üéâ\n",
        "Before moving to Phase 2, make sure you've:\n",
        "- [x] Imported all necessary libraries\n",
        "- [x] Configured display settings\n",
        "- [x] Checked PyTorch installation\n",
        "- [x] Loaded both train and test datasets\n",
        "- [x] Examined basic dataset information\n",
        "\n",
        "**Phase 1 Status: ‚úÖ COMPLETE**\n",
        "\n",
        "---"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "# Phase 2: Exploratory Data Analysis (EDA) üîç\n",
        "\n",
        "## üéØ Learning Objectives\n",
        "- Understand the distribution of the target variable (SalePrice)\n",
        "- Identify missing values in the dataset\n",
        "- Analyze correlations between features and target\n",
        "- Visualize key relationships\n",
        "- Identify important features for modeling\n",
        "\n",
        "## üìñ Key Concepts\n",
        "\n",
        "**Why EDA matters:**\n",
        "- Understanding your data prevents modeling mistakes\n",
        "- Missing values need to be handled before training\n",
        "- Feature correlations help with feature selection\n",
        "- Outliers can hurt model performance\n",
        "\n",
        "**Important Note:** The competition metric is **RMSE of log(SalePrice)**, so we'll need to consider log transformation!\n",
        "\n",
        "---"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {},
      "outputs": [],
      "source": [
        "# TODO 2.1: Analyze the Target Variable\n",
        "# Create visualizations for SalePrice:\n",
        "# - Histogram with KDE\n",
        "# - Box plot to identify outliers\n",
        "# - Calculate and print basic statistics (mean, median, std, min, max)\n",
        "# - Check if the distribution is skewed (hint: .skew())\n",
        "\n",
        "# HINT: Use plt.subplot() to create multiple plots, sns.histplot(), sns.boxplot()\n",
        "\n",
        "# Your code here:\n",
        "\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {},
      "outputs": [],
      "source": [
        "# TODO 2.2: Visualize Log-Transformed Target\n",
        "# Create a histogram of log(SalePrice) - this is what we'll actually predict!\n",
        "# Compare the skewness before and after log transformation\n",
        "# Use np.log1p() which is log(1+x) to handle any zeros safely\n",
        "\n",
        "# HINT: np.log1p(train_df['SalePrice']).hist()\n",
        "\n",
        "# Your code here:\n",
        "\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {},
      "outputs": [],
      "source": [
        "# TODO 2.3: Missing Values Analysis\n",
        "# Calculate the percentage of missing values for each column\n",
        "# Display only columns with missing values, sorted by percentage (highest first)\n",
        "# Create a visualization showing missing value percentages\n",
        "\n",
        "# HINT: Use .isnull().sum(), calculate percentages, filter where > 0, sort_values()\n",
        "# For visualization: sns.barplot() works well\n",
        "\n",
        "# Your code here:\n",
        "\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {},
      "outputs": [],
      "source": [
        "# TODO 2.4: Correlation Analysis\n",
        "# Calculate correlation of all NUMERICAL features with SalePrice\n",
        "# Display the top 10 most positively correlated features\n",
        "# Display the top 5 most negatively correlated features\n",
        "# Create a heatmap of correlations for the top 10 features\n",
        "\n",
        "# HINT: Select numerical columns using .select_dtypes(include=[np.number])\n",
        "# Use .corr() to get correlation matrix, then select 'SalePrice' column\n",
        "# For heatmap: sns.heatmap() with annot=True\n",
        "\n",
        "# Your code here:\n",
        "\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {},
      "outputs": [],
      "source": [
        "# TODO 2.5: Visualize Key Relationships\n",
        "# Create scatter plots for the top 3 most correlated features vs SalePrice\n",
        "# Add trend lines to see the relationships clearly\n",
        "# Identify any outliers that might need handling\n",
        "\n",
        "# HINT: Use plt.subplot() to create 1x3 grid\n",
        "# sns.regplot() shows scatter + trend line\n",
        "\n",
        "# Your code here:\n",
        "\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {},
      "outputs": [],
      "source": [
        "# TODO 2.6: Categorical Features Analysis\n",
        "# Identify all categorical features\n",
        "# For 2-3 interesting categorical features, create box plots showing SalePrice distribution by category\n",
        "# Examples: Neighborhood, OverallQual, HouseStyle\n",
        "\n",
        "# HINT: Use .select_dtypes(include=['object']) for categorical features\n",
        "# sns.boxplot() with x=categorical, y='SalePrice'\n",
        "\n",
        "# Your code here:\n",
        "\n"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "---\n",
        "\n",
        "## ‚úÖ Phase 2 Checklist\n",
        "Before moving to Phase 3, make sure you've:\n",
        "- [ ] Analyzed SalePrice distribution and skewness\n",
        "- [ ] Identified all columns with missing values\n",
        "- [ ] Found the most correlated features with SalePrice\n",
        "- [ ] Created visualizations for key relationships\n",
        "- [ ] Identified potential outliers\n",
        "- [ ] Analyzed categorical features\n",
        "\n",
        "**Key Insights to Note:**\n",
        "- Which features have the highest correlation with SalePrice?\n",
        "- Which features have the most missing values?\n",
        "- Is the target variable skewed? (It should be - consider log transformation!)\n",
        "\n",
        "---"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "# Phase 3: Data Preprocessing üîÑ\n",
        "\n",
        "## üéØ Learning Objectives\n",
        "- Handle missing values with appropriate imputation strategies\n",
        "- Separate numerical and categorical features\n",
        "- Encode categorical variables for ML models\n",
        "- Handle outliers\n",
        "- Engineer new features from existing ones\n",
        "\n",
        "## üìñ Key Concepts\n",
        "\n",
        "**Missing Value Strategies:**\n",
        "- Numerical: Mean, median, or specific value (e.g., 0 for missing garage size)\n",
        "- Categorical: Mode or 'None' category\n",
        "- Drop if >50% missing (be careful!)\n",
        "\n",
        "**Feature Engineering:**\n",
        "Creating new features can improve model performance significantly!\n",
        "- TotalSF = 1stFlrSF + 2ndFlrSF + TotalBsmtSF\n",
        "- TotalBath = FullBath + 0.5*HalfBath\n",
        "- HouseAge = YrSold - YearBuilt\n",
        "\n",
        "---"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {},
      "outputs": [],
      "source": [
        "# TODO 3.1: Create a Copy for Processing\n",
        "# Create copies of train and test dataframes to preserve originals\n",
        "# We'll call them 'train' and 'test'\n",
        "\n",
        "# HINT: Use .copy() to avoid modifying original data\n",
        "\n",
        "# Your code here:\n",
        "\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {},
      "outputs": [],
      "source": [
        "# TODO 3.2: Save the Target Variable\n",
        "# Extract the target variable (SalePrice) from training data\n",
        "# Apply log transformation: y = np.log1p(SalePrice)\n",
        "# Drop SalePrice from the training dataframe\n",
        "# Store test IDs for later submission\n",
        "\n",
        "# HINT: y_train = np.log1p(train['SalePrice'])\n",
        "# test_ids = test['Id']\n",
        "# Use .drop() to remove columns\n",
        "\n",
        "# Your code here:\n",
        "\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {},
      "outputs": [],
      "source": [
        "# TODO 3.3: Handle Missing Values - Numerical Features\n",
        "# For numerical columns with missing values:\n",
        "# - LotFrontage: Fill with median\n",
        "# - GarageYrBlt: Fill with YearBuilt (makes sense - garage built with house)\n",
        "# - Garage features (GarageCars, GarageArea): Fill with 0 (no garage)\n",
        "# - Basement features (BsmtFinSF1, BsmtFinSF2, BsmtUnfSF, TotalBsmtSF): Fill with 0 (no basement)\n",
        "# - MasVnrArea: Fill with 0 (no masonry veneer)\n",
        "\n",
        "# HINT: Use .fillna() method\n",
        "# Apply same transformations to both train and test!\n",
        "\n",
        "# Your code here:\n",
        "\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {},
      "outputs": [],
      "source": [
        "# TODO 3.4: Handle Missing Values - Categorical Features\n",
        "# For categorical columns with missing values:\n",
        "# - For features where missing means 'None' (e.g., PoolQC, Fence, Alley), fill with 'None'\n",
        "# - For features where missing is random (e.g., Electrical), fill with mode (most common value)\n",
        "# - Check data description to understand what missing means for each feature!\n",
        "\n",
        "# HINT: Use .fillna('None') or .fillna(train[column].mode()[0])\n",
        "# Features that likely mean 'None': PoolQC, MiscFeature, Alley, Fence, FireplaceQu,\n",
        "#                                   GarageType, GarageFinish, GarageQual, GarageCond,\n",
        "#                                   BsmtQual, BsmtCond, BsmtExposure, BsmtFinType1, BsmtFinType2,\n",
        "#                                   MasVnrType\n",
        "\n",
        "# Your code here:\n",
        "\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {},
      "outputs": [],
      "source": [
        "# TODO 3.5: Feature Engineering\n",
        "# Create new features that might be useful:\n",
        "# - TotalSF: Total square footage (1stFlrSF + 2ndFlrSF + TotalBsmtSF)\n",
        "# - TotalBath: Total bathrooms (FullBath + 0.5*HalfBath + BsmtFullBath + 0.5*BsmtHalfBath)\n",
        "# - HouseAge: Age of house (YrSold - YearBuilt)\n",
        "# - RemodAge: Years since remodeling (YrSold - YearRemodAdd)\n",
        "# - TotalPorchSF: Total porch area (OpenPorchSF + EnclosedPorch + 3SsnPorch + ScreenPorch)\n",
        "\n",
        "# HINT: Simply add columns with arithmetic operations\n",
        "# train['TotalSF'] = train['1stFlrSF'] + train['2ndFlrSF'] + train['TotalBsmtSF']\n",
        "\n",
        "# Your code here:\n",
        "\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {},
      "outputs": [],
      "source": [
        "# TODO 3.6: Handle Outliers\n",
        "# Based on EDA, remove extreme outliers that don't make sense\n",
        "# Common outliers in this dataset:\n",
        "# - Houses with GrLivArea > 4000 but SalePrice < 300000 (huge house, low price - error?)\n",
        "# - You can visualize: plt.scatter(train['GrLivArea'], y_train)\n",
        "\n",
        "# HINT: Use boolean indexing to filter\n",
        "# Remember to also filter y_train to match!\n",
        "\n",
        "# Your code here:\n",
        "\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {},
      "outputs": [],
      "source": [
        "# TODO 3.7: Encode Categorical Variables\n",
        "# Use one-hot encoding (pd.get_dummies) to convert categorical variables to numbers\n",
        "# Apply to both train and test datasets\n",
        "# Use drop_first=True to avoid multicollinearity\n",
        "\n",
        "# HINT: train = pd.get_dummies(train, drop_first=True)\n",
        "# Make sure to apply to both train and test!\n",
        "# After encoding, train and test might have different columns - we'll handle this in next TODO\n",
        "\n",
        "# Your code here:\n",
        "\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {},
      "outputs": [],
      "source": [
        "# TODO 3.8: Align Train and Test Columns\n",
        "# After one-hot encoding, train and test might have different columns\n",
        "# Align them to have the same columns (use .align() method)\n",
        "# Fill any missing values with 0\n",
        "\n",
        "# HINT: train, test = train.align(test, join='left', axis=1, fill_value=0)\n",
        "\n",
        "# Your code here:\n",
        "\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {},
      "outputs": [],
      "source": [
        "# TODO 3.9: Final Verification\n",
        "# Print the shapes of train and test\n",
        "# Check for any remaining missing values\n",
        "# Print the number of features after preprocessing\n",
        "\n",
        "# Your code here:\n",
        "\n"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "---\n",
        "\n",
        "## ‚úÖ Phase 3 Checklist\n",
        "Before moving to Phase 4, make sure you've:\n",
        "- [ ] Handled all missing values (both numerical and categorical)\n",
        "- [ ] Created new engineered features\n",
        "- [ ] Removed outliers\n",
        "- [ ] One-hot encoded all categorical variables\n",
        "- [ ] Aligned train and test columns\n",
        "- [ ] Verified no missing values remain\n",
        "\n",
        "---"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "# Phase 4: Feature Scaling & Selection ‚öñÔ∏è\n",
        "\n",
        "## üéØ Learning Objectives\n",
        "- Understand why feature scaling is critical for neural networks\n",
        "- Apply StandardScaler to normalize features\n",
        "- Split data into training and validation sets\n",
        "- Convert data to PyTorch tensors\n",
        "\n",
        "## üìñ Key Concepts\n",
        "\n",
        "**Why Scale Features?**\n",
        "- Neural networks train faster with scaled features\n",
        "- Features with large values can dominate the learning process\n",
        "- Standardization: (x - mean) / std ‚Üí mean=0, std=1\n",
        "\n",
        "**Important:** \n",
        "- Fit scaler on training data only!\n",
        "- Transform both train and validation using the same scaler\n",
        "- Save the scaler for test predictions\n",
        "\n",
        "---"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {},
      "outputs": [],
      "source": [
        "# TODO 4.1: Import Scaling and Splitting Tools\n",
        "# Import:\n",
        "# - train_test_split from sklearn.model_selection\n",
        "# - StandardScaler from sklearn.preprocessing\n",
        "\n",
        "# Your code here:\n",
        "\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {},
      "outputs": [],
      "source": [
        "# TODO 4.2: Train-Validation Split\n",
        "# Split your training data into train and validation sets\n",
        "# Use 80-20 split (test_size=0.2)\n",
        "# Set random_state=42 for reproducibility\n",
        "# Variables: X_train, X_val, y_train_split, y_val\n",
        "\n",
        "# HINT: from sklearn.model_selection import train_test_split\n",
        "# X_train, X_val, y_train_split, y_val = train_test_split(train, y_train, test_size=0.2, random_state=42)\n",
        "\n",
        "# Your code here:\n",
        "\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {},
      "outputs": [],
      "source": [
        "# TODO 4.3: Feature Scaling\n",
        "# Create a StandardScaler instance\n",
        "# Fit it on X_train only (never on validation or test!)\n",
        "# Transform X_train, X_val, and test using the fitted scaler\n",
        "# Store results in X_train_scaled, X_val_scaled, test_scaled\n",
        "\n",
        "# HINT: \n",
        "# scaler = StandardScaler()\n",
        "# X_train_scaled = scaler.fit_transform(X_train)\n",
        "# X_val_scaled = scaler.transform(X_val)\n",
        "\n",
        "# Your code here:\n",
        "\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {},
      "outputs": [],
      "source": [
        "# TODO 4.4: Convert to PyTorch Tensors\n",
        "# Convert all arrays to PyTorch tensors with dtype=torch.float32\n",
        "# Variables needed:\n",
        "# - X_train_tensor, X_val_tensor, test_tensor (features)\n",
        "# - y_train_tensor, y_val_tensor (targets)\n",
        "\n",
        "# HINT: torch.tensor(array, dtype=torch.float32)\n",
        "# For y, reshape to (n, 1) using .reshape(-1, 1)\n",
        "\n",
        "# Your code here:\n",
        "\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {},
      "outputs": [],
      "source": [
        "# TODO 4.5: Verify Tensor Shapes\n",
        "# Print the shapes of all tensors\n",
        "# Print the number of features (this is your input size for the network!)\n",
        "# Verify data types are float32\n",
        "\n",
        "# Your code here:\n",
        "\n"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "---\n",
        "\n",
        "## ‚úÖ Phase 4 Checklist\n",
        "Before moving to Phase 5, make sure you've:\n",
        "- [ ] Split data into train and validation sets (80-20)\n",
        "- [ ] Scaled features using StandardScaler\n",
        "- [ ] Converted all data to PyTorch tensors (float32)\n",
        "- [ ] Verified tensor shapes are correct\n",
        "- [ ] Noted the number of input features for your network\n",
        "\n",
        "---"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "# Phase 5: Neural Network for Regression üèóÔ∏è\n",
        "\n",
        "## üéØ Learning Objectives\n",
        "- Design a neural network architecture for regression\n",
        "- Understand the difference between classification and regression networks\n",
        "- Implement dropout for regularization\n",
        "- Choose appropriate loss function and optimizer\n",
        "\n",
        "## üìñ Key Concepts\n",
        "\n",
        "**Regression vs Classification Network:**\n",
        "\n",
        "```python\n",
        "# Classification (10 classes):\n",
        "self.output = nn.Linear(64, 10)  # 10 neurons\n",
        "# No activation - CrossEntropyLoss includes softmax\n",
        "\n",
        "# Regression (continuous value):\n",
        "self.output = nn.Linear(64, 1)   # 1 neuron\n",
        "# No activation - we want raw continuous output\n",
        "```\n",
        "\n",
        "**Loss Functions for Regression:**\n",
        "- MSELoss (L2): Penalizes large errors heavily\n",
        "- L1Loss (MAE): More robust to outliers\n",
        "- HuberLoss: Combination of both\n",
        "\n",
        "**Suggested Architecture:**\n",
        "```\n",
        "Input (n features) ‚Üí 256 ‚Üí ReLU ‚Üí Dropout(0.2)\n",
        "                   ‚Üí 128 ‚Üí ReLU ‚Üí Dropout(0.2)\n",
        "                   ‚Üí 64  ‚Üí ReLU\n",
        "                   ‚Üí 1   (output)\n",
        "```\n",
        "\n",
        "---"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {},
      "outputs": [],
      "source": [
        "# TODO 5.1: Define the Neural Network Class\n",
        "# Create a class called HousePricePredictor that inherits from nn.Module\n",
        "# Architecture:\n",
        "# - Input layer: takes n_features as input\n",
        "# - Hidden layer 1: 256 neurons + ReLU + Dropout(0.2)\n",
        "# - Hidden layer 2: 128 neurons + ReLU + Dropout(0.2)\n",
        "# - Hidden layer 3: 64 neurons + ReLU\n",
        "# - Output layer: 1 neuron (NO activation function!)\n",
        "\n",
        "# HINT: Similar to Digit Recognizer but:\n",
        "# - Output layer has 1 neuron instead of 10\n",
        "# - No activation on output layer\n",
        "# - Add dropout layers: nn.Dropout(0.2)\n",
        "\n",
        "# Your code here:\n",
        "\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {},
      "outputs": [],
      "source": [
        "# TODO 5.2: Initialize the Model\n",
        "# Create an instance of your HousePricePredictor\n",
        "# Pass the correct number of input features (from your tensors)\n",
        "# Move model to the appropriate device (GPU if available)\n",
        "# Print the model architecture\n",
        "\n",
        "# HINT: \n",
        "# n_features = X_train_tensor.shape[1]\n",
        "# model = HousePricePredictor(n_features).to(device)\n",
        "\n",
        "# Your code here:\n",
        "\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {},
      "outputs": [],
      "source": [
        "# TODO 5.3: Define Loss Function and Optimizer\n",
        "# Loss function: Use MSELoss (Mean Squared Error) for regression\n",
        "# Optimizer: Use Adam with learning_rate=0.001\n",
        "\n",
        "# HINT:\n",
        "# criterion = nn.MSELoss()\n",
        "# optimizer = torch.optim.Adam(model.parameters(), lr=0.001)\n",
        "\n",
        "# Your code here:\n",
        "\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {},
      "outputs": [],
      "source": [
        "# TODO 5.4: Count Parameters\n",
        "# Calculate and print the total number of trainable parameters in your model\n",
        "# This helps you understand model complexity\n",
        "\n",
        "# HINT: sum(p.numel() for p in model.parameters() if p.requires_grad)\n",
        "\n",
        "# Your code here:\n",
        "\n"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "---\n",
        "\n",
        "## ‚úÖ Phase 5 Checklist\n",
        "Before moving to Phase 6, make sure you've:\n",
        "- [ ] Defined HousePricePredictor class with correct architecture\n",
        "- [ ] Output layer has 1 neuron (for regression)\n",
        "- [ ] Added dropout layers for regularization\n",
        "- [ ] Initialized model with correct input size\n",
        "- [ ] Defined MSELoss criterion\n",
        "- [ ] Initialized Adam optimizer\n",
        "- [ ] Counted model parameters\n",
        "\n",
        "---"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "# Phase 6: Training Pipeline üöÇ\n",
        "\n",
        "## üéØ Learning Objectives\n",
        "- Create DataLoaders for efficient batch training\n",
        "- Implement training loop with validation\n",
        "- Track regression metrics (MSE, RMSE, MAE, R¬≤)\n",
        "- Visualize training progress\n",
        "- Save the best model\n",
        "\n",
        "## üìñ Key Concepts\n",
        "\n",
        "**Regression Metrics:**\n",
        "- **MSE** (Mean Squared Error): Average of squared errors\n",
        "- **RMSE** (Root MSE): Square root of MSE - same units as target\n",
        "- **MAE** (Mean Absolute Error): Average of absolute errors\n",
        "- **R¬≤** (R-squared): How much variance is explained (1.0 is perfect)\n",
        "\n",
        "**Training Process:**\n",
        "1. Forward pass: Get predictions\n",
        "2. Calculate loss\n",
        "3. Backward pass: Calculate gradients\n",
        "4. Update weights\n",
        "5. Validate and track metrics\n",
        "\n",
        "---"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {},
      "outputs": [],
      "source": [
        "# TODO 6.1: Import Additional Tools\n",
        "# Import:\n",
        "# - TensorDataset, DataLoader from torch.utils.data\n",
        "# - mean_squared_error, mean_absolute_error, r2_score from sklearn.metrics\n",
        "\n",
        "# Your code here:\n",
        "\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {},
      "outputs": [],
      "source": [
        "# TODO 6.2: Create DataLoaders\n",
        "# Create TensorDatasets for train and validation\n",
        "# Create DataLoaders with batch_size=32\n",
        "# Shuffle training data, don't shuffle validation\n",
        "\n",
        "# HINT:\n",
        "# train_dataset = TensorDataset(X_train_tensor, y_train_tensor)\n",
        "# train_loader = DataLoader(train_dataset, batch_size=32, shuffle=True)\n",
        "\n",
        "# Your code here:\n",
        "\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {},
      "outputs": [],
      "source": [
        "# TODO 6.3: Implement Training Loop\n",
        "# Create a training loop that:\n",
        "# - Trains for a specified number of epochs (start with 100)\n",
        "# - For each epoch:\n",
        "#   * Train on batches\n",
        "#   * Calculate training loss\n",
        "#   * Validate on validation set\n",
        "#   * Calculate validation metrics (MSE, RMSE, MAE, R¬≤)\n",
        "#   * Track losses and metrics\n",
        "#   * Print progress every 10 epochs\n",
        "#   * Save best model based on validation RMSE\n",
        "\n",
        "# HINT: Similar to Digit Recognizer but:\n",
        "# - Use MSE loss instead of CrossEntropyLoss\n",
        "# - No torch.max() for predictions - just use output.squeeze()\n",
        "# - Calculate RMSE = sqrt(MSE)\n",
        "# - For R¬≤: use sklearn.metrics.r2_score(y_true, y_pred)\n",
        "\n",
        "# Structure:\n",
        "# 1. Initialize lists to track metrics\n",
        "# 2. Set number of epochs\n",
        "# 3. For each epoch:\n",
        "#    a. Training phase (model.train())\n",
        "#    b. Validation phase (model.eval())\n",
        "#    c. Calculate and store metrics\n",
        "#    d. Save best model\n",
        "\n",
        "# Your code here:\n",
        "\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {},
      "outputs": [],
      "source": [
        "# TODO 6.4: Visualize Training Progress\n",
        "# Create plots showing:\n",
        "# - Training and validation loss over epochs\n",
        "# - Validation RMSE over epochs\n",
        "# - Validation R¬≤ over epochs\n",
        "\n",
        "# HINT: Use plt.subplot() to create multiple plots\n",
        "# Plot both train and val losses on same plot for comparison\n",
        "\n",
        "# Your code here:\n",
        "\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {},
      "outputs": [],
      "source": [
        "# TODO 6.5: Evaluate Best Model\n",
        "# Load the best saved model\n",
        "# Evaluate on validation set\n",
        "# Print final metrics:\n",
        "# - Validation RMSE\n",
        "# - Validation MAE\n",
        "# - Validation R¬≤\n",
        "\n",
        "# HINT: model.load_state_dict(torch.load('best_model.pth'))\n",
        "\n",
        "# Your code here:\n",
        "\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {},
      "outputs": [],
      "source": [
        "# TODO 6.6: Prediction vs Actual Plot\n",
        "# Create a scatter plot of predicted vs actual values on validation set\n",
        "# Add a diagonal line showing perfect predictions\n",
        "# This visualizes how well the model performs\n",
        "\n",
        "# HINT:\n",
        "# plt.scatter(y_val_actual, y_val_pred, alpha=0.5)\n",
        "# plt.plot([min, max], [min, max], 'r--')  # diagonal line\n",
        "\n",
        "# Your code here:\n",
        "\n"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "---\n",
        "\n",
        "## ‚úÖ Phase 6 Checklist\n",
        "Before moving to Phase 7, make sure you've:\n",
        "- [ ] Created DataLoaders for batching\n",
        "- [ ] Implemented complete training loop\n",
        "- [ ] Tracked training and validation losses\n",
        "- [ ] Calculated regression metrics (RMSE, MAE, R¬≤)\n",
        "- [ ] Saved the best model\n",
        "- [ ] Visualized training progress\n",
        "- [ ] Created prediction vs actual plot\n",
        "\n",
        "**Target Performance:**\n",
        "- Validation RMSE < 0.15 (good)\n",
        "- Validation RMSE < 0.13 (great!)\n",
        "- R¬≤ > 0.85 (good fit)\n",
        "\n",
        "---"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "# Phase 7: Evaluation & Submission üìä\n",
        "\n",
        "## üéØ Learning Objectives\n",
        "- Generate predictions on test data\n",
        "- Create Kaggle submission file\n",
        "- Validate submission format\n",
        "- Document and save model\n",
        "- (Optional) Compare with traditional ML models\n",
        "\n",
        "## üìñ Key Concepts\n",
        "\n",
        "**Important Steps:**\n",
        "1. Load best model\n",
        "2. Predict on test set (already scaled)\n",
        "3. **Reverse log transformation** (critical!)\n",
        "4. Create submission.csv\n",
        "5. Validate format\n",
        "\n",
        "**Remember:** We predicted log(SalePrice), so we need to reverse it:\n",
        "```python\n",
        "predictions = np.expm1(log_predictions)  # exp(x) - 1\n",
        "```\n",
        "\n",
        "---"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {},
      "outputs": [],
      "source": [
        "# TODO 7.1: Load Best Model and Generate Test Predictions\n",
        "# Load your best saved model\n",
        "# Set model to eval mode\n",
        "# Generate predictions on test set\n",
        "# Remember to move test tensor to the same device as model\n",
        "\n",
        "# HINT:\n",
        "# model.load_state_dict(torch.load('best_model.pth'))\n",
        "# model.eval()\n",
        "# with torch.no_grad():\n",
        "#     predictions = model(test_tensor.to(device))\n",
        "\n",
        "# Your code here:\n",
        "\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {},
      "outputs": [],
      "source": [
        "# TODO 7.2: Reverse Log Transformation\n",
        "# Convert predictions from log scale back to actual prices\n",
        "# Use np.expm1() which is the inverse of np.log1p()\n",
        "# Convert to numpy array and flatten if needed\n",
        "\n",
        "# HINT:\n",
        "# predictions_log = predictions.cpu().numpy().flatten()\n",
        "# predictions_price = np.expm1(predictions_log)\n",
        "\n",
        "# Your code here:\n",
        "\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {},
      "outputs": [],
      "source": [
        "# TODO 7.3: Create Submission File\n",
        "# Create a DataFrame with columns: ['Id', 'SalePrice']\n",
        "# Id should be from test_ids you saved earlier\n",
        "# SalePrice should be your predictions (in original scale!)\n",
        "# Save to '../submission.csv'\n",
        "\n",
        "# HINT:\n",
        "# submission = pd.DataFrame({\n",
        "#     'Id': test_ids,\n",
        "#     'SalePrice': predictions_price\n",
        "# })\n",
        "# submission.to_csv('../submission.csv', index=False)\n",
        "\n",
        "# Your code here:\n",
        "\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {},
      "outputs": [],
      "source": [
        "# TODO 7.4: Validate Submission Format\n",
        "# Load the submission file and check:\n",
        "# - Columns are ['Id', 'SalePrice']\n",
        "# - Shape is (1459, 2)\n",
        "# - No missing values\n",
        "# - All prices are positive\n",
        "# - Display first few rows\n",
        "\n",
        "# Your code here:\n",
        "\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {},
      "outputs": [],
      "source": [
        "# TODO 7.5: Save Model and Metadata\n",
        "# Save:\n",
        "# - Model state dict to '../trained_models/house_price_model.pth'\n",
        "# - Model metadata (architecture, performance, date) to '../trained_models/model_metadata.json'\n",
        "# - Scaler object using joblib to '../trained_models/scaler.pkl'\n",
        "\n",
        "# HINT:\n",
        "# torch.save(model.state_dict(), '../trained_models/house_price_model.pth')\n",
        "# import json, joblib\n",
        "\n",
        "# Your code here:\n",
        "\n"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "---\n",
        "\n",
        "## üéâ Optional: Compare with Traditional ML Models\n",
        "\n",
        "Want to go further? Compare your neural network with traditional models!\n",
        "\n",
        "---"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {},
      "outputs": [],
      "source": [
        "# OPTIONAL TODO 7.6: Linear Regression Baseline\n",
        "# Train a simple Linear Regression model for comparison\n",
        "# Evaluate on validation set\n",
        "# Compare RMSE with your neural network\n",
        "\n",
        "# HINT:\n",
        "# from sklearn.linear_model import LinearRegression\n",
        "# lr = LinearRegression()\n",
        "# lr.fit(X_train_scaled, y_train_split)\n",
        "# predictions = lr.predict(X_val_scaled)\n",
        "\n",
        "# Your code here:\n",
        "\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {},
      "outputs": [],
      "source": [
        "# OPTIONAL TODO 7.7: Random Forest Model\n",
        "# Train a Random Forest regressor\n",
        "# Evaluate and compare with neural network\n",
        "\n",
        "# HINT:\n",
        "# from sklearn.ensemble import RandomForestRegressor\n",
        "# rf = RandomForestRegressor(n_estimators=100, random_state=42)\n",
        "# rf.fit(X_train_scaled, y_train_split.ravel())\n",
        "\n",
        "# Your code here:\n",
        "\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {},
      "outputs": [],
      "source": [
        "# OPTIONAL TODO 7.8: Model Comparison Table\n",
        "# Create a comparison table showing:\n",
        "# Model | RMSE | MAE | R¬≤ | Training Time\n",
        "# For: Neural Network, Linear Regression, Random Forest\n",
        "\n",
        "# Your code here:\n",
        "\n"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "---\n",
        "\n",
        "## ‚úÖ Phase 7 Checklist\n",
        "Before finalizing, make sure you've:\n",
        "- [ ] Generated predictions on test set\n",
        "- [ ] Reversed log transformation\n",
        "- [ ] Created submission.csv\n",
        "- [ ] Validated submission format\n",
        "- [ ] Saved model and metadata\n",
        "- [ ] (Optional) Compared with traditional ML models\n",
        "\n",
        "---\n",
        "\n",
        "## üöÄ Next Steps\n",
        "\n",
        "1. **Submit to Kaggle:**\n",
        "   - Go to [competition page](https://www.kaggle.com/c/house-prices-advanced-regression-techniques)\n",
        "   - Click \"Submit Predictions\"\n",
        "   - Upload your `submission.csv`\n",
        "\n",
        "2. **Update README.md:**\n",
        "   - Add your final results\n",
        "   - Include visualizations\n",
        "   - Document your learning journey\n",
        "\n",
        "3. **Create MODEL_CARD.md:**\n",
        "   - Document architecture\n",
        "   - Performance metrics\n",
        "   - Training details\n",
        "\n",
        "4. **Git Commit:**\n",
        "   - Commit your completed notebook\n",
        "   - Push to GitHub\n",
        "\n",
        "---\n",
        "\n",
        "## üéì What You've Learned\n",
        "\n",
        "Congratulations! Through this project, you've learned:\n",
        "\n",
        "‚úÖ **Regression with Neural Networks**\n",
        "- Output layer design for continuous predictions\n",
        "- Appropriate loss functions (MSELoss)\n",
        "- Regression metrics (RMSE, MAE, R¬≤)\n",
        "\n",
        "‚úÖ **Feature Engineering**\n",
        "- Creating new features from existing ones\n",
        "- Feature scaling and normalization\n",
        "- Handling mixed data types\n",
        "\n",
        "‚úÖ **Data Preprocessing**\n",
        "- Missing value imputation strategies\n",
        "- One-hot encoding categorical variables\n",
        "- Outlier detection and handling\n",
        "\n",
        "‚úÖ **Model Evaluation**\n",
        "- Proper train/validation split\n",
        "- Tracking multiple metrics\n",
        "- Comparing different model types\n",
        "\n",
        "‚úÖ **Production Skills**\n",
        "- Saving models and scalers for deployment\n",
        "- Creating submission files for competitions\n",
        "- Documenting models with metadata\n",
        "\n",
        "---\n",
        "\n",
        "## üí™ Keep Learning!\n",
        "\n",
        "Ready for more challenges?\n",
        "- Try ensemble methods (combining multiple models)\n",
        "- Experiment with feature selection techniques\n",
        "- Learn about XGBoost and LightGBM\n",
        "- Explore AutoML tools\n",
        "\n",
        "Great job! üéâ"
      ]
    }
  ],
  "metadata": {
    "kernelspec": {
      "display_name": "Codecademy ML",
      "language": "python",
      "name": "codeacademy"
    },
    "language_info": {
      "codemirror_mode": {
        "name": "ipython",
        "version": 3
      },
      "file_extension": ".py",
      "mimetype": "text/x-python",
      "name": "python",
      "nbconvert_exporter": "python",
      "pygments_lexer": "ipython3",
      "version": "3.11.7"
    }
  },
  "nbformat": 4,
  "nbformat_minor": 4
}
